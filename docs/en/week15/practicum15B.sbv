0:00:01.920,0:00:08.160
so we share the screen

0:00:05.040,0:00:10.240
and i'm opening the chat

0:00:08.160,0:00:12.160
all right so i have the chat open so you

0:00:10.240,0:00:14.240
can interact with me

0:00:12.160,0:00:16.480
and so a small recap from last time last

0:00:14.240,0:00:19.359
time we've been talking about energy

0:00:16.480,0:00:20.080
uh and actually we've been talking about

0:00:19.359,0:00:23.119
inference

0:00:20.080,0:00:24.560
how to find set how to find y check uh

0:00:23.119,0:00:28.160
how to compute y

0:00:24.560,0:00:30.080
f and e okay and so let me just start

0:00:28.160,0:00:32.160
i guess with the the last slide from

0:00:30.080,0:00:35.120
last time so we

0:00:32.160,0:00:35.920
had computed this f infinity uh which is

0:00:35.120,0:00:39.680
called

0:00:35.920,0:00:42.480
uh zero temperature limit uh free energy

0:00:39.680,0:00:44.239
uh as a function of my y and y is going

0:00:42.480,0:00:46.399
to be a two dimensional

0:00:44.239,0:00:47.360
vector right so whenever i'm going to be

0:00:46.399,0:00:49.520
plotting this f

0:00:47.360,0:00:51.520
infinity of y it's going to be a scalar

0:00:49.520,0:00:55.120
field means this a height

0:00:51.520,0:00:57.840
over like a 2d region okay

0:00:55.120,0:00:59.039
so we saw already this stuff that since

0:00:57.840,0:01:00.800
it's gonna have different height i'm

0:00:59.039,0:01:03.840
gonna represent with the

0:01:00.800,0:01:07.760
color purple the height equals zero

0:01:03.840,0:01:09.760
and then color equal green for

0:01:07.760,0:01:10.960
equal one and then everything that is

0:01:09.760,0:01:14.240
above and beyond

0:01:10.960,0:01:14.799
the free energy equal tool is going to

0:01:14.240,0:01:18.720
be in

0:01:14.799,0:01:22.159
yellow okay and so

0:01:18.720,0:01:23.920
this is how this stuff looks i

0:01:22.159,0:01:26.240
would like to remind you that this free

0:01:23.920,0:01:29.280
energy was the quadratic

0:01:26.240,0:01:31.600
uh a cliton distance from the model

0:01:29.280,0:01:35.119
manifold right so all points that are

0:01:31.600,0:01:36.720
within the um within the model manifold

0:01:35.119,0:01:39.360
they have zero cost right

0:01:36.720,0:01:40.240
this is sorry zero energy free energy

0:01:39.360,0:01:41.759
because again the

0:01:40.240,0:01:44.240
the distance between them and the

0:01:41.759,0:01:45.840
manifold is zero so zero squared is zero

0:01:44.240,0:01:47.360
and then as you move away it's gonna

0:01:45.840,0:01:50.799
it's gonna increase up

0:01:47.360,0:01:54.159
uh quadratically so

0:01:50.799,0:01:55.920
uh so far everything should be uh

0:01:54.159,0:01:58.000
known understood and you know you you

0:01:55.920,0:01:58.719
took yeah you had one week to to go over

0:01:58.000,0:02:01.759
this stuff so

0:01:58.719,0:02:04.079
i i assume everyone is quite familiar

0:02:01.759,0:02:06.079
so something that you may notice right

0:02:04.079,0:02:07.840
now is gonna be in the side

0:02:06.079,0:02:11.039
of these ellipse you're going to have

0:02:07.840,0:02:13.200
like a region that is slightly

0:02:11.039,0:02:14.879
slightly lighter right you can see a

0:02:13.200,0:02:17.680
lighter degree of

0:02:14.879,0:02:18.879
purple so what's going on over there so

0:02:17.680,0:02:22.000
let me show you this

0:02:18.879,0:02:23.440
uh image here uh with the height

0:02:22.000,0:02:25.280
you know proportional to the actual

0:02:23.440,0:02:28.160
height of this um

0:02:25.280,0:02:30.080
of this free energy okay so i'm gonna

0:02:28.160,0:02:32.319
change the color map such that

0:02:30.080,0:02:34.239
uh you can clearly see what's going on

0:02:32.319,0:02:34.720
and i'm gonna be using this one which is

0:02:34.239,0:02:37.840
called

0:02:34.720,0:02:40.400
cold warm so cold means like

0:02:37.840,0:02:42.080
f infinity equals zero i'm going to be

0:02:40.400,0:02:45.120
using the blue color

0:02:42.080,0:02:45.680
for f infinity equal 0.5 i'm gonna be

0:02:45.120,0:02:48.400
using

0:02:45.680,0:02:50.480
a gray color and then for everything

0:02:48.400,0:02:55.120
that is above and beyond

0:02:50.480,0:02:57.680
f infinity one is going to be in red

0:02:55.120,0:02:59.680
and so this is going to be um the the

0:02:57.680,0:03:00.720
image you saw before now that was like

0:02:59.680,0:03:03.120
simply saw from

0:03:00.720,0:03:04.080
uh from top here i'm gonna show you the

0:03:03.120,0:03:07.360
contour

0:03:04.080,0:03:08.959
so each uh line here they share the same

0:03:07.360,0:03:11.519
value of the free energy

0:03:08.959,0:03:13.760
okay so let me spin this little guy so

0:03:11.519,0:03:16.560
it's that you can see all around

0:03:13.760,0:03:17.120
as you can tell all the regions like the

0:03:16.560,0:03:20.400
height

0:03:17.120,0:03:22.239
around the the the ellipse that is

0:03:20.400,0:03:23.440
with the the manifold ellipse is gonna

0:03:22.239,0:03:25.280
have zero energy

0:03:23.440,0:03:27.440
and as you move away from that you're

0:03:25.280,0:03:29.599
gonna have like a quadratic thing right

0:03:27.440,0:03:33.519
so you're gonna have like a parabola

0:03:29.599,0:03:35.120
uh what you notice is that in the center

0:03:33.519,0:03:36.799
so on the outside of course is going to

0:03:35.120,0:03:38.400
be like a parabola but in the center

0:03:36.799,0:03:39.840
those two things are going to be going

0:03:38.400,0:03:43.200
up on a peak

0:03:39.840,0:03:46.720
right and this might

0:03:43.200,0:03:48.879
or might not be wanted and so the

0:03:46.720,0:03:50.879
this we're gonna start today lesson by

0:03:48.879,0:03:53.920
learning how to relax

0:03:50.879,0:03:56.000
this uh free energy this infinite zero

0:03:53.920,0:03:58.879
temperature limit free energy

0:03:56.000,0:03:59.599
to a more you know uh a free energy

0:03:58.879,0:04:01.599
without

0:03:59.599,0:04:03.920
local minima such that you know it's a

0:04:01.599,0:04:06.080
bit more smooth

0:04:03.920,0:04:07.599
let me take here a cross section of this

0:04:06.080,0:04:10.159
you know bathtub

0:04:07.599,0:04:10.640
for y one equals zero so i'm gonna be

0:04:10.159,0:04:13.680
chaff

0:04:10.640,0:04:15.519
chopping it in a correspondence of y one

0:04:13.680,0:04:17.359
equals zero

0:04:15.519,0:04:19.359
so what we get is going to be the

0:04:17.359,0:04:22.240
following you're gonna see now

0:04:19.359,0:04:24.080
that those two branches are gonna be my

0:04:22.240,0:04:26.400
parabolic branches right

0:04:24.080,0:04:27.520
so again what is this free energy free

0:04:26.400,0:04:30.800
energy

0:04:27.520,0:04:31.919
was the square distance of your given

0:04:30.800,0:04:34.720
point

0:04:31.919,0:04:35.360
to the closest point on the manifold

0:04:34.720,0:04:37.600
right

0:04:35.360,0:04:38.759
so if you're on the manifold which is

0:04:37.600,0:04:42.400
like location

0:04:38.759,0:04:43.120
0.4 for example then the distance

0:04:42.400,0:04:45.840
between you

0:04:43.120,0:04:47.280
and the manifold is going to be zero and

0:04:45.840,0:04:48.160
therefore the square of zero is going to

0:04:47.280,0:04:50.240
be zero

0:04:48.160,0:04:52.240
as you move away let's say we move to

0:04:50.240,0:04:55.520
the right hand side of this

0:04:52.240,0:04:56.080
0.4 as you move linearly to the right

0:04:55.520,0:04:57.759
hand side

0:04:56.080,0:04:59.360
you're going to be increasing

0:04:57.759,0:05:00.320
quadratically right that's why we

0:04:59.360,0:05:02.960
observe

0:05:00.320,0:05:04.320
this energy free energy going up

0:05:02.960,0:05:06.720
quadratically

0:05:04.320,0:05:07.919
similarly what happens on the other side

0:05:06.720,0:05:09.919
of course

0:05:07.919,0:05:11.919
the same happens as you move towards the

0:05:09.919,0:05:13.120
zero right and so as you move towards

0:05:11.919,0:05:16.560
the zero you're gonna get

0:05:13.120,0:05:19.120
that you try to climb up that parabola

0:05:16.560,0:05:19.840
and we have this peak over here and so

0:05:19.120,0:05:21.680
in the next

0:05:19.840,0:05:24.160
slide we're gonna be learning how to

0:05:21.680,0:05:26.720
smooth that peak

0:05:24.160,0:05:27.840
i'll let you i tell you later why we uh

0:05:26.720,0:05:30.560
what is very why

0:05:27.840,0:05:31.039
this is very useful like why we why my

0:05:30.560,0:05:34.560
why

0:05:31.039,0:05:38.479
we might want to do so okay

0:05:34.560,0:05:39.120
so free energy we we know right the the

0:05:38.479,0:05:42.400
minimum

0:05:39.120,0:05:45.440
value of the energy e that

0:05:42.400,0:05:47.759
is spanning across y and z right so

0:05:45.440,0:05:50.639
you have this energy we saw that uh for

0:05:47.759,0:05:53.600
a given y we have like an energy over z

0:05:50.639,0:05:55.199
and then the free energy was the value

0:05:53.600,0:05:58.000
of the energy correspondent

0:05:55.199,0:05:59.600
to the location where we have the

0:05:58.000,0:06:00.479
minimum value right so the minimum value

0:05:59.600,0:06:04.080
of this

0:06:00.479,0:06:05.759
e is going to be my free energy

0:06:04.080,0:06:08.720
now i'm going to be introducing a

0:06:05.759,0:06:12.479
relaxed version which is going to be

0:06:08.720,0:06:14.880
this uh purple f so

0:06:12.479,0:06:15.600
this purple f function parameterized by

0:06:14.880,0:06:19.919
beta

0:06:15.600,0:06:21.199
is going to be simply this expression uh

0:06:19.919,0:06:24.400
what is this beta

0:06:21.199,0:06:26.479
right so this beta it's in

0:06:24.400,0:06:27.680
physics it's called the inverse

0:06:26.479,0:06:29.759
temperature

0:06:27.680,0:06:31.360
the thermo thermodynamic inverse

0:06:29.759,0:06:34.560
temperature or the

0:06:31.360,0:06:37.360
coldness and it's simply one over

0:06:34.560,0:06:40.080
uh kb which is the boltzmann constant

0:06:37.360,0:06:42.560
multiplied by the temperature okay

0:06:40.080,0:06:44.720
so again if t that capital t the

0:06:42.560,0:06:46.479
temperature is very very very high

0:06:44.720,0:06:48.080
like it's very warm like you're on the

0:06:46.479,0:06:52.160
sun beta is gonna be

0:06:48.080,0:06:54.639
extremely small right it's gonna be zero

0:06:52.160,0:06:55.919
instead if temperature the temperature

0:06:54.639,0:06:58.400
is cold like

0:06:55.919,0:06:59.599
zero kelvin then automatically you're

0:06:58.400,0:07:03.520
gonna get that beta

0:06:59.599,0:07:06.720
it's plus infinity right and so

0:07:03.520,0:07:10.240
now you can understand why

0:07:06.720,0:07:12.080
i call my f infinity the zero

0:07:10.240,0:07:15.039
temperature limit

0:07:12.080,0:07:16.160
free energy so it's zero temperature

0:07:15.039,0:07:18.800
it's super cold right

0:07:16.160,0:07:19.840
so capital t is zero meaning beta is

0:07:18.800,0:07:22.080
plus infinity

0:07:19.840,0:07:24.240
so again if you have this free energy

0:07:22.080,0:07:25.680
with so-called free energy

0:07:24.240,0:07:28.160
the free energy is going to be exactly

0:07:25.680,0:07:30.160
the minimum otherwise if you relax

0:07:28.160,0:07:31.840
this constraint as you warm up a little

0:07:30.160,0:07:33.840
bit this free energy

0:07:31.840,0:07:35.680
the free energy is going to be a

0:07:33.840,0:07:38.800
summation of multiple

0:07:35.680,0:07:40.960
things right so this s here is the s for

0:07:38.800,0:07:43.680
sum is a summation of all these

0:07:40.960,0:07:46.720
components here multiplied by the

0:07:43.680,0:07:48.879
interval cool

0:07:46.720,0:07:50.080
this symbol over here it's simply the

0:07:48.879,0:07:53.280
measure

0:07:50.080,0:07:56.319
of the domain of z so in our case

0:07:53.280,0:07:56.960
uh z goes from zero to two pi and

0:07:56.319,0:08:00.000
therefore

0:07:56.960,0:08:00.560
this item over here it simply means two

0:08:00.000,0:08:03.680
pi

0:08:00.560,0:08:07.520
okay all right all right but who

0:08:03.680,0:08:09.759
who remembers what this kbt is right

0:08:07.520,0:08:11.199
what is this kbt why are we talking

0:08:09.759,0:08:14.160
about energies right

0:08:11.199,0:08:14.960
so again from physics no 101 you might

0:08:14.160,0:08:18.000
remember that

0:08:14.960,0:08:20.319
the average

0:08:18.000,0:08:21.039
translational kinetic energy was the two

0:08:20.319,0:08:25.039
third

0:08:21.039,0:08:25.840
kbt no and therefore kbt or two third

0:08:25.039,0:08:29.199
kbt

0:08:25.840,0:08:30.080
express the uh kinetic energy right of

0:08:29.199,0:08:33.200
this

0:08:30.080,0:08:35.680
let's say gas with all those particles

0:08:33.200,0:08:36.959
and so the temperature allows you to

0:08:35.680,0:08:38.959
express

0:08:36.959,0:08:41.360
uh the energy right so you have

0:08:38.959,0:08:44.560
temperature and energy are connected

0:08:41.360,0:08:46.720
um so you can make uh

0:08:44.560,0:08:48.800
a quick you know check check here and

0:08:46.720,0:08:51.920
beta since it's going to be the inverse

0:08:48.800,0:08:55.600
of kbt it's going to be in one over

0:08:51.920,0:08:58.800
joule right and so here we have these

0:08:55.600,0:09:00.800
one over joule means that this stuff is

0:08:58.800,0:09:01.839
joule therefore f is going to be an

0:09:00.800,0:09:04.080
energy

0:09:01.839,0:09:04.880
and then inside this exponential we have

0:09:04.080,0:09:07.680
one over

0:09:04.880,0:09:09.279
joule times the e which is joule and

0:09:07.680,0:09:12.399
then if you multiply the two you

0:09:09.279,0:09:12.800
then the two you know units cancel out

0:09:12.399,0:09:16.000
so

0:09:12.800,0:09:18.560
everything works just fine

0:09:16.000,0:09:19.360
all right all right all right um and

0:09:18.560,0:09:21.760
also yes

0:09:19.360,0:09:23.279
the the dimension of z cancel out with

0:09:21.760,0:09:24.080
this dimension right so everything is

0:09:23.279,0:09:27.360
just pure

0:09:24.080,0:09:29.040
uh pure number okay again these are this

0:09:27.360,0:09:30.640
is not machine learning this is physics

0:09:29.040,0:09:32.320
just to give you a little bit of you

0:09:30.640,0:09:34.800
know uh

0:09:32.320,0:09:36.320
overview about what this stuff where

0:09:34.800,0:09:38.000
this stuff comes from right so this is

0:09:36.320,0:09:39.839
just from our friends from the physics

0:09:38.000,0:09:41.600
department

0:09:39.839,0:09:43.600
all right all right all right so i want

0:09:41.600,0:09:45.519
to compute this free energy in this

0:09:43.600,0:09:48.720
relaxed version of this

0:09:45.519,0:09:50.399
uh free energy uh since i don't want to

0:09:48.720,0:09:53.360
compute this integral

0:09:50.399,0:09:55.440
i may not know how to do that i simply

0:09:53.360,0:09:58.959
use a simple discretization right

0:09:55.440,0:10:01.519
and so i replace this latin s with a

0:09:58.959,0:10:02.320
greek s right and then i replace this

0:10:01.519,0:10:05.040
latin d

0:10:02.320,0:10:06.800
with a greek t so everything else is

0:10:05.040,0:10:09.440
just the same so i go from the

0:10:06.800,0:10:11.680
time continuous to a discretization very

0:10:09.440,0:10:13.600
simple discretization it works

0:10:11.680,0:10:15.519
in our case because z is like one

0:10:13.600,0:10:18.720
dimension i saw you know everything is

0:10:15.519,0:10:22.160
pretty easy uh

0:10:18.720,0:10:24.480
moreover here i will just define and

0:10:22.160,0:10:25.760
pay attention i am defining right now

0:10:24.480,0:10:29.200
for this class

0:10:25.760,0:10:32.880
okay this thing uh has been the

0:10:29.200,0:10:36.480
soft mean of e so my

0:10:32.880,0:10:39.120
free energy uh the purple one

0:10:36.480,0:10:39.839
it's simply the relaxation of the zero

0:10:39.120,0:10:42.079
temperature

0:10:39.839,0:10:43.120
limit is going to be simply this soft

0:10:42.079,0:10:45.360
mean so

0:10:43.120,0:10:46.560
the zero temperature the super cold one

0:10:45.360,0:10:50.000
is simply the mean

0:10:46.560,0:10:52.480
okay am i n min whereas if i

0:10:50.000,0:10:53.120
compute if i relax if i turn on the

0:10:52.480,0:10:55.680
temperature

0:10:53.120,0:10:56.640
like i increase the thermostat i'm gonna

0:10:55.680,0:10:59.760
have this

0:10:56.640,0:11:02.399
soft mean which is this log

0:10:59.760,0:11:03.360
summation of exponential okay and i call

0:11:02.399,0:11:05.920
this actual

0:11:03.360,0:11:07.279
soft mean why do i call it actual soft

0:11:05.920,0:11:10.560
meme because other people

0:11:07.279,0:11:12.720
uh most of the people outside this class

0:11:10.560,0:11:14.000
will call this the soft means something

0:11:12.720,0:11:16.480
else and i will let you

0:11:14.000,0:11:18.480
know a bit more about these in a few

0:11:16.480,0:11:21.920
slides okay

0:11:18.480,0:11:25.680
something that is super interesting is

0:11:21.920,0:11:29.440
computing the limit of this free energy

0:11:25.680,0:11:31.440
here for beta that goes to zero so

0:11:29.440,0:11:33.120
whenever you increase the temperature

0:11:31.440,0:11:35.279
as the temperature on the sun like it's

0:11:33.120,0:11:39.200
super warm what is the most

0:11:35.279,0:11:41.920
relaxed version of this min

0:11:39.200,0:11:43.360
and so if you do that you're gonna see

0:11:41.920,0:11:46.480
that

0:11:43.360,0:11:48.320
this stuff ends up being the average but

0:11:46.480,0:11:50.720
again this is just you know

0:11:48.320,0:11:51.519
um it's not relevant it's not too

0:11:50.720,0:11:54.720
important

0:11:51.519,0:11:55.120
uh is the derivation just i can show you

0:11:54.720,0:11:56.959
here

0:11:55.120,0:11:58.240
and i just show you so you can you have

0:11:56.959,0:12:01.279
access later

0:11:58.240,0:12:03.920
uh the limit of this free energy

0:12:01.279,0:12:04.399
for beta that goes to zero so it's very

0:12:03.920,0:12:06.959
warm

0:12:04.399,0:12:07.920
super warm it ends up being simply the

0:12:06.959,0:12:11.839
average

0:12:07.920,0:12:15.279
of the energy okay across those heads

0:12:11.839,0:12:17.200
again not to uh you don't have to get

0:12:15.279,0:12:19.440
scared about that math

0:12:17.200,0:12:20.800
all right so let's compute this free

0:12:19.440,0:12:23.040
energy for

0:12:20.800,0:12:24.079
the cases we saw before right so we are

0:12:23.040,0:12:25.920
still doing inference

0:12:24.079,0:12:27.760
as last time but instead of using the

0:12:25.920,0:12:29.360
cold inference the cold free energy

0:12:27.760,0:12:30.560
we're going to use this you know relaxed

0:12:29.360,0:12:34.000
version

0:12:30.560,0:12:37.279
for the y equal 23 so if you remember

0:12:34.000,0:12:39.440
the y equal 23 was this x

0:12:37.279,0:12:42.160
the green x on the right hand side and

0:12:39.440,0:12:44.800
then here the free energy was the square

0:12:42.160,0:12:46.560
of the distance between the blue x and

0:12:44.800,0:12:49.440
the green x right so the

0:12:46.560,0:12:52.240
the distance was 0.5 square would would

0:12:49.440,0:12:53.519
have been 0.25 and that would have been

0:12:52.240,0:12:56.240
the free energy

0:12:53.519,0:12:57.040
uh zero temperature zero zero

0:12:56.240,0:12:59.680
temperature

0:12:57.040,0:13:01.440
limit free energy but in this case we

0:12:59.680,0:13:04.399
have now to consider

0:13:01.440,0:13:05.120
all these contributions and so i'm gonna

0:13:04.399,0:13:08.959
show you

0:13:05.120,0:13:12.560
how all those little

0:13:08.959,0:13:15.920
z dz will contribute to this free energy

0:13:12.560,0:13:19.519
and so we choose a beta equal 1

0:13:15.920,0:13:21.760
and we have now this so given that y

0:13:19.519,0:13:23.760
prime is going to be this x on the right

0:13:21.760,0:13:27.600
hand side

0:13:23.760,0:13:31.040
my free energy now comes from the

0:13:27.600,0:13:31.920
addition of all these uh terms here the

0:13:31.040,0:13:35.120
exponential

0:13:31.920,0:13:38.399
of you know minus the energy of

0:13:35.120,0:13:40.000
all of this right so all the squares

0:13:38.399,0:13:41.920
like the exponential of the negative

0:13:40.000,0:13:44.560
squares right

0:13:41.920,0:13:45.440
so as you can tell those points that are

0:13:44.560,0:13:48.560
close to the

0:13:45.440,0:13:50.240
x will have like a

0:13:48.560,0:13:51.920
smaller energy and therefore the

0:13:50.240,0:13:54.480
exponential will be larger

0:13:51.920,0:13:55.920
and that's why you can see them but for

0:13:54.480,0:13:58.320
energy that are you know

0:13:55.920,0:14:00.240
further away that are very high energy

0:13:58.320,0:14:01.839
you do not do the exponential of main

0:14:00.240,0:14:04.079
minus and large number you're going to

0:14:01.839,0:14:07.040
get basically zero so they don't count

0:14:04.079,0:14:09.120
in this summation in this integral okay

0:14:07.040,0:14:12.560
first question for people at home

0:14:09.120,0:14:17.600
to just check if you are following

0:14:12.560,0:14:20.079
how that where does 0.75 come from

0:14:17.600,0:14:21.120
so where does this value over here come

0:14:20.079,0:14:23.760
from

0:14:21.120,0:14:25.279
and you're supposed to type on the chart

0:14:23.760,0:14:27.920
such that i can read

0:14:25.279,0:14:29.199
aloud what you're saying so i'm asking

0:14:27.920,0:14:33.680
once again

0:14:29.199,0:14:36.240
where does this value over here 075

0:14:33.680,0:14:36.240
come from

0:14:39.440,0:14:45.839
and someone is to reply

0:14:47.480,0:14:53.440
contribution to the energy yes yes no

0:14:49.760,0:14:56.399
the number 075 i i need you to tell me

0:14:53.440,0:14:58.240
how to compute 0.75 where does that

0:14:56.399,0:15:02.399
number come from

0:14:58.240,0:15:04.560
you have all these closest why

0:15:02.399,0:15:05.600
till then yeah tell me uh how do i how

0:15:04.560,0:15:08.800
do i compute

0:15:05.600,0:15:08.800
1 over 2 pi no

0:15:10.880,0:15:17.600
x okay x minus beta e okay so how much

0:15:15.199,0:15:17.600
is e

0:15:19.839,0:15:23.440
e is the square distance right so how

0:15:22.240,0:15:26.639
much is it

0:15:23.440,0:15:30.240
how much is okay e is 0 25

0:15:26.639,0:15:34.079
correct and so e to the minus

0:15:30.240,0:15:37.120
0 25 is going to be 0 75

0:15:34.079,0:15:40.160
correct okay

0:15:37.120,0:15:43.360
so jc got the right answer

0:15:40.160,0:15:43.839
good job so great now we know where that

0:15:43.360,0:15:45.680
number

0:15:43.839,0:15:48.000
comes from so every time you see this

0:15:45.680,0:15:49.600
diagram so although it looks very sparse

0:15:48.000,0:15:51.839
and pretty and whatever you always have

0:15:49.600,0:15:52.800
to pay attention to the number i put on

0:15:51.839,0:15:54.560
this

0:15:52.800,0:15:57.120
on the screen right so those numbers are

0:15:54.560,0:16:00.560
not random number they are

0:15:57.120,0:16:03.519
computed by my computer and you always

0:16:00.560,0:16:04.160
always always have to check on a piece

0:16:03.519,0:16:06.720
of paper

0:16:04.160,0:16:08.240
that these numbers make sense because if

0:16:06.720,0:16:09.600
they don't make sense

0:16:08.240,0:16:11.600
then you're not understanding what's

0:16:09.600,0:16:12.560
going on okay so you have to pay

0:16:11.600,0:16:15.600
attention

0:16:12.560,0:16:18.240
to the numbers and you know

0:16:15.600,0:16:19.519
okay i'm a physicist right so you always

0:16:18.240,0:16:22.480
i always

0:16:19.519,0:16:23.839
uh have in advance in my mind the answer

0:16:22.480,0:16:26.079
that my program my

0:16:23.839,0:16:28.000
network my whatever is supposed to do

0:16:26.079,0:16:29.600
right if i make an electronic circuit i

0:16:28.000,0:16:31.360
must understand

0:16:29.600,0:16:32.720
i must know in advance what is the you

0:16:31.360,0:16:34.720
know voltage somewhere

0:16:32.720,0:16:36.399
here and there before i actually measure

0:16:34.720,0:16:39.600
it otherwise uh

0:16:36.399,0:16:41.759
you know it don't go much ahead

0:16:39.600,0:16:43.680
all right all right all right so let's

0:16:41.759,0:16:46.480
move on and let's now consider

0:16:43.680,0:16:47.519
instead the case for when i have y y

0:16:46.480,0:16:51.279
prime

0:16:47.519,0:16:52.240
equal 10 right so the 10th item so which

0:16:51.279,0:16:55.839
is the

0:16:52.240,0:16:58.560
element on the top there so in this case

0:16:55.839,0:16:59.839
i'm gonna get that all those points here

0:16:58.560,0:17:02.160
will contribute

0:16:59.839,0:17:06.400
to the free energy right in this case

0:17:02.160,0:17:09.520
we're gonna have a number to 0.26

0:17:06.400,0:17:12.799
27 okay someone else that is not jesse

0:17:09.520,0:17:15.039
uh can write on the chat how much

0:17:12.799,0:17:17.039
where that number comes from so where

0:17:15.039,0:17:18.799
does 026 come from

0:17:17.039,0:17:21.439
i think you must have understand

0:17:18.799,0:17:21.439
understood now

0:17:22.559,0:17:30.160
e to the minus 1 kind of yes so

0:17:26.559,0:17:31.600
so the distance here is 1.1 1.1 square

0:17:30.160,0:17:34.000
is going to be 1.2

0:17:31.600,0:17:36.160
and then you take e to the minus 1.2

0:17:34.000,0:17:38.640
which is 0 26 yeah

0:17:36.160,0:17:39.919
that's correct all right all right all

0:17:38.640,0:17:42.960
right okay so

0:17:39.919,0:17:47.840
next question uh what happens now

0:17:42.960,0:17:47.840
if my y prime is going to be the origin

0:17:48.480,0:17:53.760
so what happens if my y prime is the

0:17:52.000,0:17:54.559
origin for the zero temperature you're

0:17:53.760,0:17:57.280
going to get the

0:17:54.559,0:17:59.440
square the distance right from either

0:17:57.280,0:18:03.120
side

0:17:59.440,0:18:04.400
in this case what's going to be the main

0:18:03.120,0:18:05.919
difference if you warm up the

0:18:04.400,0:18:06.880
temperature right so you're not zero

0:18:05.919,0:18:08.240
temperature it's not

0:18:06.880,0:18:09.520
it's not freezing cold we are going to

0:18:08.240,0:18:10.559
be increasing a little bit the

0:18:09.520,0:18:13.919
temperature

0:18:10.559,0:18:14.400
and how is this free energy changing

0:18:13.919,0:18:19.360
from

0:18:14.400,0:18:19.360
before anyone can type on the chart

0:18:20.000,0:18:24.400
it's symmetric yeah that's perfect how

0:18:23.120,0:18:26.320
do you know

0:18:24.400,0:18:28.240
you already saw the slides before oh you

0:18:26.320,0:18:31.919
actually got it right

0:18:28.240,0:18:31.919
okay i assume you got it right

0:18:32.000,0:18:35.360
all right okay that's perfect yes it's

0:18:33.760,0:18:38.559
symmetric right so

0:18:35.360,0:18:42.559
uh a point now inside

0:18:38.559,0:18:43.120
oh okay yeah i don't know if it's a he

0:18:42.559,0:18:45.120
or she

0:18:43.120,0:18:46.720
but studied physics in the undergrad

0:18:45.120,0:18:49.919
okay cool

0:18:46.720,0:18:52.320
all right uh so

0:18:49.919,0:18:54.080
in this case you have again that all

0:18:52.320,0:18:56.640
those points on the top on the bottom

0:18:54.080,0:18:58.720
will contribute to the free energy uh

0:18:56.640,0:19:01.760
given that i choose that y

0:18:58.720,0:19:04.880
uh y prime to be in the center okay

0:19:01.760,0:19:06.320
all right so that's pretty much oh

0:19:04.880,0:19:09.520
but why we are talking why are we

0:19:06.320,0:19:12.640
talking about this right so we came here

0:19:09.520,0:19:14.720
because we had that issue with the

0:19:12.640,0:19:17.600
picky picky center right i showed you

0:19:14.720,0:19:19.360
before that spinning bathtub

0:19:17.600,0:19:21.280
and then the cross-section here that we

0:19:19.360,0:19:23.120
had this picky thing

0:19:21.280,0:19:24.720
which was coming from the cold free

0:19:23.120,0:19:26.799
energy let's

0:19:24.720,0:19:29.679
let me show you what happens now if i

0:19:26.799,0:19:32.880
choose the warm free energy right

0:19:29.679,0:19:35.919
and so if i do that i'm gonna get if i

0:19:32.880,0:19:35.919
can scroll my screen

0:19:37.600,0:19:40.880
oh you don't see anything okay let me

0:19:39.679,0:19:43.840
click click

0:19:40.880,0:19:44.400
okay all right and so the red one was

0:19:43.840,0:19:47.120
the

0:19:44.400,0:19:47.919
super cold the beta is the coldness

0:19:47.120,0:19:51.120
again so

0:19:47.919,0:19:52.799
large beta is called and then we

0:19:51.120,0:19:54.880
reduce the coldness so we increase the

0:19:52.799,0:19:57.840
temperature and as you can see the

0:19:54.880,0:19:58.720
the picky part becomes smooth smooth

0:19:57.840,0:20:02.400
smooth

0:19:58.720,0:20:05.120
until it becomes oh

0:20:02.400,0:20:06.159
becomes some a parabola with a single

0:20:05.120,0:20:09.200
global

0:20:06.159,0:20:11.600
minima oh

0:20:09.200,0:20:15.039
this is coming out to be remember what

0:20:11.600,0:20:17.200
happens if beta goes to zero

0:20:15.039,0:20:21.200
you get the average right so you

0:20:17.200,0:20:24.559
actually recover the msc

0:20:21.200,0:20:28.480
okay i'm just giving like small uh

0:20:24.559,0:20:31.360
small like information bits

0:20:28.480,0:20:31.919
pills whatever but again yeah so

0:20:31.360,0:20:33.679
whenever

0:20:31.919,0:20:35.679
we increase the temperature you're going

0:20:33.679,0:20:36.799
to be relaxing until you get just one

0:20:35.679,0:20:38.320
single minimum

0:20:36.799,0:20:40.559
and then there are no more latent

0:20:38.320,0:20:43.840
because we just average out everything

0:20:40.559,0:20:46.480
without those weights right anyhow

0:20:43.840,0:20:47.440
uh i i think now if you if you need to

0:20:46.480,0:20:49.440
implement this stuff

0:20:47.440,0:20:52.000
in pytorch you're gonna be be getting

0:20:49.440,0:20:54.640
like quite frustrated because

0:20:52.000,0:20:55.280
they use different names for the things

0:20:54.640,0:20:58.000
i just

0:20:55.280,0:20:59.440
defined and someone say oh you should

0:20:58.000,0:21:01.679
have used their names no

0:20:59.440,0:21:04.159
because those are wrong right so i use

0:21:01.679,0:21:06.400
the correct name so the one that is

0:21:04.159,0:21:07.520
that makes sense i will try to sell it

0:21:06.400,0:21:09.760
to you this way

0:21:07.520,0:21:12.159
so let me explain to you a little bit of

0:21:09.760,0:21:15.039
you know what is the nomenclature i use

0:21:12.159,0:21:15.440
uh such that it makes sense at least to

0:21:15.039,0:21:18.240
me

0:21:15.440,0:21:19.760
otherwise things don't make sense to me

0:21:18.240,0:21:21.600
so this is the actual

0:21:19.760,0:21:23.440
soft max right not the soft max that

0:21:21.600,0:21:25.039
people talk outside this class this is

0:21:23.440,0:21:27.840
the actual soft max

0:21:25.039,0:21:29.679
which is this you know one over betas

0:21:27.840,0:21:31.039
log of blah blah blah some of the

0:21:29.679,0:21:34.640
exponentials

0:21:31.039,0:21:38.000
i just expanded these um the previous

0:21:34.640,0:21:40.000
uh i just expanded the the one over z

0:21:38.000,0:21:42.480
i took it out right in the in the

0:21:40.000,0:21:44.159
logarithm so i just split the two things

0:21:42.480,0:21:46.480
so how do we implement this stuff in

0:21:44.159,0:21:49.360
pytorch well you just use this function

0:21:46.480,0:21:52.640
which is called torch dot log sum x

0:21:49.360,0:21:53.120
which is this soft max actual softmax

0:21:52.640,0:21:55.600
right

0:21:53.120,0:21:56.880
and then plus or minus that additional

0:21:55.600,0:21:58.960
constant over there

0:21:56.880,0:22:00.240
right so this is how you want to use how

0:21:58.960,0:22:03.440
to implement that

0:22:00.240,0:22:06.559
because you know it's numerically stable

0:22:03.440,0:22:08.320
moreover if you

0:22:06.559,0:22:10.240
this is the actual definition of the

0:22:08.320,0:22:12.640
actual soft min

0:22:10.240,0:22:14.240
and you can see this is what i wrote

0:22:12.640,0:22:16.240
before

0:22:14.240,0:22:17.840
you can think about that it's very

0:22:16.240,0:22:19.360
similar to the softmax right

0:22:17.840,0:22:21.520
the actual softmax what's the only

0:22:19.360,0:22:24.240
difference there are two minuses right

0:22:21.520,0:22:24.880
and so you can do that you can get get

0:22:24.240,0:22:26.640
that away

0:22:24.880,0:22:28.400
with you know you put a minus in front

0:22:26.640,0:22:30.480
so you cancel the first minus

0:22:28.400,0:22:31.760
and you put a minus inside so you cancel

0:22:30.480,0:22:34.320
the other minus

0:22:31.760,0:22:36.240
and so you know the soft mean is simply

0:22:34.320,0:22:38.400
uh you can implement it as a

0:22:36.240,0:22:40.559
soft max with the two minuses okay

0:22:38.400,0:22:42.320
against actual softmax

0:22:40.559,0:22:43.760
and then someone of course is going to

0:22:42.320,0:22:46.000
be asking

0:22:43.760,0:22:48.480
but what is the softmax we use in class

0:22:46.000,0:22:51.840
every time so that one

0:22:48.480,0:22:55.120
is actually the soft arc max right

0:22:51.840,0:22:56.880
why is that right because a arc max is

0:22:55.120,0:23:00.000
going to be like a one hot vector

0:22:56.880,0:23:02.799
and d1 tells you what is the index

0:23:00.000,0:23:04.000
of the element that has the maximum

0:23:02.799,0:23:06.720
value right

0:23:04.000,0:23:08.000
so the max gives you retrieves the

0:23:06.720,0:23:10.240
maximum value

0:23:08.000,0:23:12.400
you know and then the arc max is going

0:23:10.240,0:23:14.320
to tell you where is the index

0:23:12.400,0:23:15.840
pointing to that maximum value right so

0:23:14.320,0:23:18.000
this is like a vector

0:23:15.840,0:23:19.200
with a one hot vector and the other one

0:23:18.000,0:23:21.440
is a scalar

0:23:19.200,0:23:23.600
similarly whenever i compute this soft

0:23:21.440,0:23:26.159
max the softer version of the max

0:23:23.600,0:23:28.400
now this max is not just the max it's

0:23:26.159,0:23:30.880
going to be like a summation of this

0:23:28.400,0:23:32.640
uh the logarithm of the summation of the

0:23:30.880,0:23:34.400
exponential right

0:23:32.640,0:23:36.080
which you can change the temperature if

0:23:34.400,0:23:37.200
you get the temperature super cold you

0:23:36.080,0:23:38.720
retrieve the max

0:23:37.200,0:23:41.039
if you warm up the temperature you get

0:23:38.720,0:23:43.840
something like more

0:23:41.039,0:23:45.039
like a weighted summation and for the

0:23:43.840,0:23:46.880
soft dark max

0:23:45.039,0:23:48.960
which was like the arc max is the one

0:23:46.880,0:23:50.640
hot if it's super cold

0:23:48.960,0:23:52.080
it's gonna still be one hot but if you

0:23:50.640,0:23:53.600
warm up the temperature

0:23:52.080,0:23:55.679
you're gonna get a distribution

0:23:53.600,0:23:58.000
probability distribution right

0:23:55.679,0:23:59.200
so whenever someone says oh the soft max

0:23:58.000,0:24:01.360
gives you the probability distribution

0:23:59.200,0:24:04.159
now that's the soft dark mask okay

0:24:01.360,0:24:06.000
uh arc max being the one hot or the zero

0:24:04.159,0:24:06.720
temperature limited limit gives you the

0:24:06.000,0:24:08.080
one hot

0:24:06.720,0:24:10.000
if you increase the temperature you get

0:24:08.080,0:24:12.799
a distribution so finally

0:24:10.000,0:24:14.080
these are the correct names no one is

0:24:12.799,0:24:18.159
using but me

0:24:14.080,0:24:21.360
so i hope i didn't create confusion

0:24:18.159,0:24:24.960
if i did sorry but still this is the

0:24:21.360,0:24:27.840
correct way of seeing these things okay

0:24:24.960,0:24:28.799
because it makes sense right so again uh

0:24:27.840,0:24:31.279
if you have the

0:24:28.799,0:24:32.000
max if you have a function you want to

0:24:31.279,0:24:34.640
find the

0:24:32.000,0:24:36.080
max it's here right if you have this

0:24:34.640,0:24:38.240
function you want to find the mean

0:24:36.080,0:24:39.679
you can take the function you flip it

0:24:38.240,0:24:41.039
you find the max

0:24:39.679,0:24:42.559
and then you flip it back again you get

0:24:41.039,0:24:43.039
the mean right so that's what i show you

0:24:42.559,0:24:45.600
here

0:24:43.039,0:24:46.880
i show you that soft min is simply the

0:24:45.600,0:24:50.799
flipped version

0:24:46.880,0:24:54.000
the negative right of the max with a

0:24:50.799,0:24:55.919
flipped in argument okay

0:24:54.000,0:24:57.039
all right all right so enough me talking

0:24:55.919,0:24:59.919
about

0:24:57.039,0:25:01.520
mathematics and things i hope it was

0:24:59.919,0:25:05.200
fine

0:25:01.520,0:25:08.640
so this was the part

0:25:05.200,0:25:09.440
uh that was concluding the last lesson

0:25:08.640,0:25:12.880
right so

0:25:09.440,0:25:14.880
this is the end of the inference

0:25:12.880,0:25:16.000
and we figured that there is the free

0:25:14.880,0:25:18.880
energy

0:25:16.000,0:25:19.679
there is a very cold one or there is a

0:25:18.880,0:25:21.520
warm

0:25:19.679,0:25:23.120
version or there is a very hot version

0:25:21.520,0:25:24.080
the hot version is going to be the

0:25:23.120,0:25:25.760
average

0:25:24.080,0:25:27.600
the warm version is going to be like

0:25:25.760,0:25:30.400
something you you may like

0:25:27.600,0:25:31.200
is like this marginalization of the of

0:25:30.400,0:25:33.360
the latent

0:25:31.200,0:25:34.720
and then the super cold version the zero

0:25:33.360,0:25:37.200
temperature limit is going to be

0:25:34.720,0:25:39.200
this exactly the minimum version minimum

0:25:37.200,0:25:42.480
value

0:25:39.200,0:25:45.120
uh what i showed you was the fact that

0:25:42.480,0:25:45.919
this model is a very poorly trained

0:25:45.120,0:25:49.120
model

0:25:45.919,0:25:51.760
because those low energy

0:25:49.120,0:25:53.679
regions were not you know happening

0:25:51.760,0:25:56.480
around this training set right so

0:25:53.679,0:25:58.080
let me show you once again uh the same

0:25:56.480,0:26:00.480
and the same diagram i showed you

0:25:58.080,0:26:02.080
at the beginning of today's lesson which

0:26:00.480,0:26:04.320
is this one over here

0:26:02.080,0:26:05.520
so here i show you with these white

0:26:04.320,0:26:08.559
checks a few

0:26:05.520,0:26:12.240
uh samples uh on the

0:26:08.559,0:26:14.000
model manifold and then the y's the blue

0:26:12.240,0:26:15.520
eyes are the training sample but we

0:26:14.000,0:26:17.200
never use the training sample right i

0:26:15.520,0:26:20.080
just use the training sample to

0:26:17.200,0:26:21.039
compute the energy the free energy but

0:26:20.080,0:26:22.799
we never

0:26:21.039,0:26:24.480
use them to learn because we didn't talk

0:26:22.799,0:26:27.679
about learning we talked about

0:26:24.480,0:26:29.120
inference so far right and so

0:26:27.679,0:26:31.600
guess what is going to be the next part

0:26:29.120,0:26:34.080
of today's lesson

0:26:31.600,0:26:35.360
you guessed it right training so now

0:26:34.080,0:26:38.640
we're going to be starting

0:26:35.360,0:26:39.120
uh to learn how to train learn how to

0:26:38.640,0:26:41.440
learn

0:26:39.120,0:26:42.640
train train how to learn no learn how to

0:26:41.440,0:26:45.600
train

0:26:42.640,0:26:48.960
energy based model okay unless there are

0:26:45.600,0:26:48.960
questions for me on the chat

0:26:50.320,0:26:55.760
no questions everything clear meta

0:26:53.039,0:26:57.600
learning yes

0:26:55.760,0:26:59.919
no that one is a different subject next

0:26:57.600,0:26:59.919
time

0:27:00.159,0:27:04.720
all right okay so i think yeah there is

0:27:02.960,0:27:06.880
no big deal right so this is just

0:27:04.720,0:27:08.799
inference we didn't talk about any crazy

0:27:06.880,0:27:09.279
stuff and we talked in for inference

0:27:08.799,0:27:11.039
about

0:27:09.279,0:27:12.559
about the inference the whole last

0:27:11.039,0:27:15.360
lesson so

0:27:12.559,0:27:17.840
i guess we can move on move on and start

0:27:15.360,0:27:20.320
the training

0:27:17.840,0:27:21.279
finding a well-behaved energy function

0:27:20.320,0:27:24.080
right

0:27:21.279,0:27:25.200
what does this mean so this means we

0:27:24.080,0:27:27.840
have to introduce

0:27:25.200,0:27:30.240
a loss functional what's a loss

0:27:27.840,0:27:33.679
functional

0:27:30.240,0:27:35.440
well it's a metric it's a scalar

0:27:33.679,0:27:38.640
function

0:27:35.440,0:27:42.000
that is telling you how good your

0:27:38.640,0:27:44.559
energy function is right so we have an

0:27:42.000,0:27:45.520
energy function which is this free

0:27:44.559,0:27:47.360
energy

0:27:45.520,0:27:49.279
and then we're going to have a function

0:27:47.360,0:27:51.039
of my function

0:27:49.279,0:27:53.840
which is giving me a scalar which is

0:27:51.039,0:27:56.880
just telling me how good this

0:27:53.840,0:27:59.520
energy function is right so

0:27:56.880,0:28:00.240
a loss functional gives me a scalar

0:27:59.520,0:28:03.679
given that i

0:28:00.240,0:28:06.320
feed a function

0:28:03.679,0:28:07.679
and here i just show to you that if i

0:28:06.320,0:28:10.720
have this curly l

0:28:07.679,0:28:13.600
as you know the loss functional for the

0:28:10.720,0:28:15.840
all the whole batch my whole data set i

0:28:13.600,0:28:19.600
can also express this as the average

0:28:15.840,0:28:21.600
of these per sample loss functionals

0:28:19.600,0:28:23.919
okay so i just do the average of those

0:28:21.600,0:28:26.640
per sample those functions

0:28:23.919,0:28:28.559
cool so what the heck am i talking about

0:28:26.640,0:28:30.720
right so i'm just giving you i'm

0:28:28.559,0:28:32.080
making so much hype but i didn't tell

0:28:30.720,0:28:33.520
you anything so far

0:28:32.080,0:28:35.120
and we already know this stuff from you

0:28:33.520,0:28:37.840
know machine learning and you know

0:28:35.120,0:28:39.360
previous lessons and so here we go with

0:28:37.840,0:28:41.520
the first loss function

0:28:39.360,0:28:43.200
which is the which is the energy loss

0:28:41.520,0:28:46.240
function

0:28:43.200,0:28:49.360
so this energy loss functional

0:28:46.240,0:28:52.720
it's simply the free energy

0:28:49.360,0:28:54.720
f evaluated in my y

0:28:52.720,0:28:56.840
where y is the data point on the data

0:28:54.720,0:28:59.840
set right

0:28:56.840,0:29:01.600
so whenever whenever we train these

0:28:59.840,0:29:03.200
models we're going to be minimizing the

0:29:01.600,0:29:06.399
loss functionalities

0:29:03.200,0:29:08.000
right the loss function and so in this

0:29:06.399,0:29:11.120
case the loss functional

0:29:08.000,0:29:14.399
is actually the free energy at the

0:29:11.120,0:29:17.440
training point of course right i mean

0:29:14.399,0:29:18.559
what this energy function has to do with

0:29:17.440,0:29:21.200
the free energy

0:29:18.559,0:29:22.559
should be small for data that comes from

0:29:21.200,0:29:25.279
the training distribution

0:29:22.559,0:29:26.960
large elsewhere right and so what is the

0:29:25.279,0:29:28.480
easiest way to do that well of course

0:29:26.960,0:29:31.679
we're gonna just have the

0:29:28.480,0:29:34.799
loss functional being the free energy

0:29:31.679,0:29:37.600
evaluated at the training point

0:29:34.799,0:29:39.440
so if it's larger than zero then the

0:29:37.600,0:29:41.039
training of the network you know

0:29:39.440,0:29:42.960
changing the parameters such that we

0:29:41.039,0:29:45.520
minimize the loss functional

0:29:42.960,0:29:47.120
is going to be squeezing down the free

0:29:45.520,0:29:48.640
energy on those

0:29:47.120,0:29:50.399
points right so you have the point you

0:29:48.640,0:29:53.679
have a free energy boom

0:29:50.399,0:29:56.799
point free energy bomb all right so

0:29:53.679,0:29:58.480
we just small like clamp like we

0:29:56.799,0:30:00.559
we are reducing the free energy in

0:29:58.480,0:30:04.000
correspondence to all these

0:30:00.559,0:30:06.000
uh whites why is

0:30:04.000,0:30:07.120
there is a check there is a check

0:30:06.000,0:30:08.960
because i

0:30:07.120,0:30:10.240
want to emphasize the fact that we are

0:30:08.960,0:30:12.240
trying to push down

0:30:10.240,0:30:13.440
the energy at those locations right so i

0:30:12.240,0:30:16.799
push down there is the

0:30:13.440,0:30:19.600
arrow pointing down i push down

0:30:16.799,0:30:20.960
all right okay i might sound silly but

0:30:19.600,0:30:24.880
it doesn't matter i like

0:30:20.960,0:30:26.320
myself silly so instead now we're gonna

0:30:24.880,0:30:28.399
be introducing these

0:30:26.320,0:30:29.520
uh contrastive methods what is a

0:30:28.399,0:30:32.080
contrastive method

0:30:29.520,0:30:32.720
uh in this case this contrasting method

0:30:32.080,0:30:35.440
will have

0:30:32.720,0:30:36.399
a white check which is blue why is blue

0:30:35.440,0:30:38.320
because it's cold

0:30:36.399,0:30:40.320
right so we want to try to get low

0:30:38.320,0:30:41.600
energy again the energy the temperature

0:30:40.320,0:30:44.399
are connected right

0:30:41.600,0:30:46.320
so low energy is going to be cold blue

0:30:44.399,0:30:50.159
and then i have a white hot

0:30:46.320,0:30:51.520
why is hot why is red why why hot is red

0:30:50.159,0:30:53.679
i want to increase the energy right

0:30:51.520,0:30:56.720
that's why there is the the hot pointing

0:30:53.679,0:31:00.080
upwards and so in this case

0:30:56.720,0:31:04.000
uh given that m is a positive number

0:31:00.080,0:31:08.480
the difference f of y hat

0:31:04.000,0:31:10.880
minus f of y check that the difference

0:31:08.480,0:31:11.760
it will the network will try to make it

0:31:10.880,0:31:15.360
larger than

0:31:11.760,0:31:19.039
m right so for as long as the difference

0:31:15.360,0:31:22.159
is smaller than m then these

0:31:19.039,0:31:22.559
you know this value over here will have

0:31:22.159,0:31:25.919
a

0:31:22.559,0:31:29.519
positive value whenever f y hat

0:31:25.919,0:31:32.799
minus f y check will be larger than

0:31:29.519,0:31:34.240
m then you're gonna have that

0:31:32.799,0:31:36.000
you know the output of this stuff is

0:31:34.240,0:31:38.880
gonna be zero

0:31:36.000,0:31:39.360
okay because there is a a positive part

0:31:38.880,0:31:42.559
so

0:31:39.360,0:31:42.880
again this hinge loss will simply try to

0:31:42.559,0:31:45.919
get

0:31:42.880,0:31:46.720
that second difference to be larger than

0:31:45.919,0:31:50.960
the

0:31:46.720,0:31:50.960
uh the first term the margin

0:31:51.039,0:31:54.640
in order to have like a smoother version

0:31:53.120,0:31:56.960
of this margin

0:31:54.640,0:31:58.799
this is like very binary right if you're

0:31:56.960,0:32:01.279
lower than the margin you push

0:31:58.799,0:32:03.120
larger than the margin you stop pushing

0:32:01.279,0:32:07.679
you can use this other version the

0:32:03.120,0:32:10.799
the loss log loss functional

0:32:07.679,0:32:13.279
which is a smooth margin uh

0:32:10.799,0:32:14.399
you can you can see right whenever you

0:32:13.279,0:32:17.440
have that

0:32:14.399,0:32:18.240
inside these in this parenthesis you

0:32:17.440,0:32:20.399
have a very

0:32:18.240,0:32:21.679
negative number so if this is very very

0:32:20.399,0:32:23.600
large and this is zero

0:32:21.679,0:32:25.360
let's say you're gonna have the x of a

0:32:23.600,0:32:25.919
very negative number which is roughly

0:32:25.360,0:32:28.080
zero

0:32:25.919,0:32:29.279
and i have the log of one which is you

0:32:28.080,0:32:32.240
know stop pushing

0:32:29.279,0:32:33.600
there is no more instead if this value

0:32:32.240,0:32:35.840
here is large

0:32:33.600,0:32:37.600
and this value is maybe negative or

0:32:35.840,0:32:38.880
whatever is zero

0:32:37.600,0:32:40.640
you're gonna have the exponential of

0:32:38.880,0:32:42.799
this number which is gonna be very large

0:32:40.640,0:32:44.240
and then you're gonna have the one plus

0:32:42.799,0:32:47.679
this exponential

0:32:44.240,0:32:48.240
uh which again the one gets neglected

0:32:47.679,0:32:49.840
you don't get

0:32:48.240,0:32:51.840
the log of this x but you're gonna get

0:32:49.840,0:32:53.679
basically the uh the

0:32:51.840,0:32:57.279
the loss is gonna be proportional to the

0:32:53.679,0:33:00.880
energy right if it's very large

0:32:57.279,0:33:03.519
cool cool but again for our case uh

0:33:00.880,0:33:04.240
we just have a very tiny one-dimensional

0:33:03.519,0:33:06.399
latent

0:33:04.240,0:33:07.760
so we don't need to do this uh this

0:33:06.399,0:33:09.760
contrastive sampling

0:33:07.760,0:33:11.440
uh contrastive learning it's necessary

0:33:09.760,0:33:13.440
whenever you have like a

0:33:11.440,0:33:14.720
um you know maybe like a high

0:33:13.440,0:33:18.320
dimensional latent

0:33:14.720,0:33:20.080
and so on um so let's just

0:33:18.320,0:33:22.559
you know let's just train this model

0:33:20.080,0:33:26.080
because i didn't train this model so far

0:33:22.559,0:33:29.519
with this energy loss functional

0:33:26.080,0:33:31.360
okay and so i train this model it takes

0:33:29.519,0:33:33.840
one epoch to converge

0:33:31.360,0:33:36.159
it's ridiculously fast okay but it's a

0:33:33.840,0:33:38.880
toy example so you understand that

0:33:36.159,0:33:39.200
and i'm gonna start by uh showing you

0:33:38.880,0:33:41.600
the

0:33:39.200,0:33:43.519
zero temperature limit the super cold

0:33:41.600,0:33:45.200
free energy okay

0:33:43.519,0:33:46.720
uh on the left hand side i'm gonna show

0:33:45.200,0:33:48.559
you the untrained version which is the

0:33:46.720,0:33:52.000
one we already saw before

0:33:48.559,0:33:54.559
so in this case for every training

0:33:52.000,0:33:55.440
point the blue point i have a

0:33:54.559,0:33:57.919
corresponding

0:33:55.440,0:34:00.080
x which is the location on the model

0:33:57.919,0:34:04.559
manifold that is the closest to that

0:34:00.080,0:34:08.639
training point okay whenever i train

0:34:04.559,0:34:11.200
i'm gonna be you know uh get a gradient

0:34:08.639,0:34:12.000
that gradient is gonna be i just i told

0:34:11.200,0:34:13.520
you before

0:34:12.000,0:34:15.679
if you if you get the mean you're gonna

0:34:13.520,0:34:17.280
get one item and then if you do the

0:34:15.679,0:34:19.119
derivative you're gonna get the

0:34:17.280,0:34:21.040
argument which is just the one in

0:34:19.119,0:34:24.240
correspondence to the

0:34:21.040,0:34:25.919
lowest value and so that one is going to

0:34:24.240,0:34:28.960
be represented here

0:34:25.919,0:34:31.359
by uh that

0:34:28.960,0:34:32.480
arrow over here right so this arrow here

0:34:31.359,0:34:35.440
is going to be

0:34:32.480,0:34:36.320
the energy the derivative of the energy

0:34:35.440,0:34:39.599
which is going to be

0:34:36.320,0:34:42.320
just the distance like the y minus

0:34:39.599,0:34:43.440
y check and then that's going to be

0:34:42.320,0:34:45.760
multiplied by

0:34:43.440,0:34:48.240
you know the one in corresponding to the

0:34:45.760,0:34:51.280
location that is closest to uh

0:34:48.240,0:34:54.879
to our point all right so

0:34:51.280,0:34:57.440
what this means is that during training

0:34:54.879,0:34:59.040
whenever we use the ztl the zero

0:34:57.440,0:35:00.720
temperature limit you're gonna get

0:34:59.040,0:35:02.240
the location on the manifold that is

0:35:00.720,0:35:03.680
closest to your training point

0:35:02.240,0:35:05.520
and then you're gonna get this point to

0:35:03.680,0:35:06.960
be moving there

0:35:05.520,0:35:08.800
you have this training point you get

0:35:06.960,0:35:09.839
this location that is on the manifold

0:35:08.800,0:35:11.200
closer to this point

0:35:09.839,0:35:13.440
and then you get a gradient that is

0:35:11.200,0:35:15.119
making going up here

0:35:13.440,0:35:16.960
same you have a training point here

0:35:15.119,0:35:19.520
close this point to the manifold here

0:35:16.960,0:35:20.160
you get this point a gradient that goes

0:35:19.520,0:35:23.359
down here

0:35:20.160,0:35:26.079
okay so this is the training procedure

0:35:23.359,0:35:28.079
when using this zero temperature limit

0:35:26.079,0:35:30.480
one epoch later

0:35:28.079,0:35:31.520
on the right hand side the train version

0:35:30.480,0:35:34.800
bam

0:35:31.520,0:35:38.720
all those axes automatically managed to

0:35:34.800,0:35:41.119
arrive to destination finished

0:35:38.720,0:35:42.400
so this is like a well-trained model

0:35:41.119,0:35:45.520
which i'll show you

0:35:42.400,0:35:46.160
where i show you the energy uh going to

0:35:45.520,0:35:48.560
zero in

0:35:46.160,0:35:50.880
in the all around like acro

0:35:48.560,0:35:52.720
corresponding to all the locations

0:35:50.880,0:35:54.640
corresponding to my training data set

0:35:52.720,0:35:58.000
right the training points the

0:35:54.640,0:36:01.359
the blue points what happens if you

0:35:58.000,0:36:05.520
have two closest point on a manifold if

0:36:01.359,0:36:08.000
for example if y is at zero zero

0:36:05.520,0:36:08.000
um

0:36:09.280,0:36:14.240
right so in the energy in the in the

0:36:12.720,0:36:15.839
zero temperature limit you're going to

0:36:14.240,0:36:17.119
get just one point it's going to be

0:36:15.839,0:36:20.320
pulled there

0:36:17.119,0:36:22.480
and this is very prone to overfitting

0:36:20.320,0:36:23.440
let's say our z is not just one

0:36:22.480,0:36:25.280
dimensional

0:36:23.440,0:36:27.119
large it's larger right so instead of

0:36:25.280,0:36:29.599
having like a ellipse you're gonna have

0:36:27.119,0:36:31.599
like a potato

0:36:29.599,0:36:33.200
if you haven't hold on let me finish the

0:36:31.599,0:36:35.040
answer if you have a potato

0:36:33.200,0:36:37.440
or potato you're gonna get all these

0:36:35.040,0:36:40.960
locations on the potato to go

0:36:37.440,0:36:44.000
to those training points and so if your

0:36:40.960,0:36:45.599
z is a high dimensional latent variable

0:36:44.000,0:36:47.599
you end up with a you start with a

0:36:45.599,0:36:49.760
potato and you end up with a porcupine

0:36:47.599,0:36:51.359
with all those peaks going uh you know

0:36:49.760,0:36:52.800
going out and this is basically

0:36:51.359,0:36:53.280
overfitting you just memorize the

0:36:52.800,0:36:55.440
training

0:36:53.280,0:36:58.320
set in our case this doesn't happen

0:36:55.440,0:37:01.680
because our latent is one dimensional so

0:36:58.320,0:37:04.320
you can't really pull spikes out

0:37:01.680,0:37:04.320
of that thing

0:37:05.119,0:37:11.839
but nevertheless we may want to figure

0:37:08.880,0:37:16.320
out how to deal with this overfitting

0:37:11.839,0:37:18.240
uh by using this you know temperature

0:37:16.320,0:37:19.839
regularization thing right so before i

0:37:18.240,0:37:21.760
show you there was a peak

0:37:19.839,0:37:23.280
if there is a zero temperature limit

0:37:21.760,0:37:25.760
then if you increase the temperature you

0:37:23.280,0:37:28.560
actually smooth out that peak

0:37:25.760,0:37:30.640
and so here i'm going to show you uh

0:37:28.560,0:37:33.359
then i answer the other question

0:37:30.640,0:37:34.079
actually let me see what happens here

0:37:33.359,0:37:36.800
how

0:37:34.079,0:37:38.800
do we update the energy function is it

0:37:36.800,0:37:41.359
parametrized with uh

0:37:38.800,0:37:42.000
oh here this is definition from last

0:37:41.359,0:37:45.520
time

0:37:42.000,0:37:47.440
right so my energy function is this one

0:37:45.520,0:37:50.480
right

0:37:47.440,0:37:52.000
where so my energy function is my model

0:37:50.480,0:37:54.240
right

0:37:52.000,0:37:56.000
which is the square difference between

0:37:54.240,0:37:57.119
the locations and because the laden for

0:37:56.000,0:37:58.640
the first component and the code of the

0:37:57.119,0:37:59.280
latent for the second component so this

0:37:58.640,0:38:03.280
is like

0:37:59.280,0:38:03.280
this is how e is parametrized right

0:38:03.359,0:38:08.079
uh does the learning interpolate between

0:38:06.400,0:38:10.880
the points

0:38:08.079,0:38:11.200
uh it asked would this algorithm learn

0:38:10.880,0:38:14.000
the

0:38:11.200,0:38:14.880
mod the whole ellipse or just the blue

0:38:14.000,0:38:17.839
points

0:38:14.880,0:38:18.640
okay so i'm getting there okay is there

0:38:17.839,0:38:20.480
a visualization

0:38:18.640,0:38:24.240
for the spikes to talk about when

0:38:20.480,0:38:26.800
overfitting yeah getting there as well

0:38:24.240,0:38:28.160
all right so we were telling like we

0:38:26.800,0:38:30.400
were talking about

0:38:28.160,0:38:32.079
how we train this energy function right

0:38:30.400,0:38:34.000
so this energy energy function

0:38:32.079,0:38:35.280
is going to be this color thing i show

0:38:34.000,0:38:37.200
you over here

0:38:35.280,0:38:39.280
and this is you know a different

0:38:37.200,0:38:39.920
representation it's simply the location

0:38:39.280,0:38:43.680
of that

0:38:39.920,0:38:46.480
uh violet ellipse

0:38:43.680,0:38:48.400
training for the zero temperature zero

0:38:46.480,0:38:49.280
temperature limit means you take that

0:38:48.400,0:38:51.760
point

0:38:49.280,0:38:53.520
of these ellipse you try to pull it up

0:38:51.760,0:38:55.760
right how you pull it up

0:38:53.520,0:38:56.800
the only two parameters we had in this

0:38:55.760,0:39:00.240
model were

0:38:56.800,0:39:03.599
w1 and w2 which were con controlling the

0:39:00.240,0:39:04.960
x radius and the y radius right so we

0:39:03.599,0:39:07.359
had two parameters

0:39:04.960,0:39:08.079
and with two parameters we try to fit

0:39:07.359,0:39:11.119
all these

0:39:08.079,0:39:11.440
y's right and so basically the network

0:39:11.119,0:39:13.599
will

0:39:11.440,0:39:15.200
like the the training procedure gradient

0:39:13.599,0:39:17.680
descent will eventually

0:39:15.200,0:39:19.200
try to change the size of this ellipse

0:39:17.680,0:39:20.880
such that it

0:39:19.200,0:39:22.240
you know expands and they're going to be

0:39:20.880,0:39:25.680
matching all those

0:39:22.240,0:39:29.040
uh blue dots okay

0:39:25.680,0:39:31.280
the spiky thing was i was saying is that

0:39:29.040,0:39:33.200
if you have a high dimensional z

0:39:31.280,0:39:34.800
like in this case z is one dimension so

0:39:33.200,0:39:36.960
you have like one line

0:39:34.800,0:39:38.800
like that if that is two dimensional

0:39:36.960,0:39:41.119
it's going to be the whole surface right

0:39:38.800,0:39:42.800
and so now it's trivial to overfit you

0:39:41.119,0:39:44.160
can move anywhere in the plane there is

0:39:42.800,0:39:46.960
no more constraint

0:39:44.160,0:39:47.359
of living on that line and so we have to

0:39:46.960,0:39:49.760
see

0:39:47.359,0:39:51.200
how we can avoid overfitting but in this

0:39:49.760,0:39:53.359
case it doesn't happen but

0:39:51.200,0:39:54.720
you know we can see now that by

0:39:53.359,0:39:57.839
increasing the temperature

0:39:54.720,0:39:59.599
we no longer pick points individually

0:39:57.839,0:40:02.720
so we are using this marginalization

0:39:59.599,0:40:06.160
this vision thingy

0:40:02.720,0:40:08.800
so on the bottom part is marginalization

0:40:06.160,0:40:11.200
on the left hand side i show you how the

0:40:08.800,0:40:14.160
training uh works right

0:40:11.200,0:40:15.440
so you have that all those locations

0:40:14.160,0:40:18.720
contribute

0:40:15.440,0:40:21.119
to these you know the gradient

0:40:18.720,0:40:22.960
are just the average of those arrows

0:40:21.119,0:40:26.079
here so given that we pick

0:40:22.960,0:40:29.680
one y that is this green x

0:40:26.079,0:40:32.960
over here you get these all these

0:40:29.680,0:40:35.280
points on this manifold will contribute

0:40:32.960,0:40:37.760
and will be attracted there here before

0:40:35.280,0:40:39.920
we have only one point gets pulled up

0:40:37.760,0:40:41.839
here we have that all these points get

0:40:39.920,0:40:44.240
pulled up right so it's much harder to

0:40:41.839,0:40:45.280
overfit something you want to pay

0:40:44.240,0:40:47.359
attention here

0:40:45.280,0:40:48.960
is that how do i compute the gradient so

0:40:47.359,0:40:50.839
the gradient

0:40:48.960,0:40:52.000
i'm computing the gradient of this soft

0:40:50.839,0:40:54.800
mean

0:40:52.000,0:40:57.040
and so automatically we are gonna get a

0:40:54.800,0:40:58.640
soft argument right so if you have a max

0:40:57.040,0:41:00.560
you do the gradient you're gonna get the

0:40:58.640,0:41:02.960
arc max or if you have a mean

0:41:00.560,0:41:04.240
the gradient is gonna be the argument

0:41:02.960,0:41:06.319
here we have a soft

0:41:04.240,0:41:08.400
mean and therefore the gradient is going

0:41:06.319,0:41:11.280
to be the soft argument

0:41:08.400,0:41:11.920
multiplied by the the derivative of this

0:41:11.280,0:41:13.680
energy

0:41:11.920,0:41:15.920
and which is going to be simply this

0:41:13.680,0:41:18.079
vector right so the energy is the square

0:41:15.920,0:41:19.520
distance if you do the derivative you're

0:41:18.079,0:41:22.640
going to get the vector which are

0:41:19.520,0:41:26.400
here shown in white and then the height

0:41:22.640,0:41:28.720
is gonna be uh basically given to you

0:41:26.400,0:41:29.440
by the you know the the vector

0:41:28.720,0:41:32.640
multiplied

0:41:29.440,0:41:36.560
by this soft argument

0:41:32.640,0:41:36.880
cool wow that's a lot to take i think

0:41:36.560,0:41:39.599
but

0:41:36.880,0:41:41.280
it's it's i think it's just great uh

0:41:39.599,0:41:44.240
finally i train the last one

0:41:41.280,0:41:45.599
and i'm gonna get something like this on

0:41:44.240,0:41:48.800
the right hand side

0:41:45.599,0:41:52.240
okay so before i show you

0:41:48.800,0:41:53.839
the cross-section for the left-hand side

0:41:52.240,0:41:55.760
the untrained version i'm going to show

0:41:53.839,0:41:56.800
you now the cross-section for this train

0:41:55.760,0:41:59.200
version

0:41:56.800,0:42:01.359
so the zero temperature limit the super

0:41:59.200,0:42:02.640
cold one i'm gonna get this red one with

0:42:01.359,0:42:05.280
a spike

0:42:02.640,0:42:05.839
and then as you increase the temperature

0:42:05.280,0:42:08.400
as you

0:42:05.839,0:42:10.079
reduce this beta we're moving up until

0:42:08.400,0:42:14.400
you get this you know average

0:42:10.079,0:42:17.359
version this parabolic uh blue one right

0:42:14.400,0:42:18.800
okay okay okay and so all of this was

0:42:17.359,0:42:22.079
about

0:42:18.800,0:42:23.680
unsupervised learning right so far we

0:42:22.079,0:42:28.400
only have seen

0:42:23.680,0:42:30.880
y's where are the x's

0:42:28.400,0:42:32.319
and so this is like yesterday night i'm

0:42:30.880,0:42:34.560
like okay maybe i don't talk about

0:42:32.319,0:42:36.079
supervised learning like i don't

0:42:34.560,0:42:38.000
how long is going to take me to now

0:42:36.079,0:42:39.040
train a model with the x's and

0:42:38.000,0:42:42.400
everything and

0:42:39.040,0:42:44.800
i don't want to do it but then

0:42:42.400,0:42:45.680
i just change one line of code and

0:42:44.800,0:42:48.000
everything just

0:42:45.680,0:42:49.920
works so everything we have seen so far

0:42:48.000,0:42:51.760
is exactly the same

0:42:49.920,0:42:53.200
for the unconditional which is this

0:42:51.760,0:42:56.240
unsupervised

0:42:53.200,0:42:57.760
learning way and it's gonna

0:42:56.240,0:43:00.240
like one line change you're gonna get

0:42:57.760,0:43:00.640
the supervised like the self-supervised

0:43:00.240,0:43:03.040
the

0:43:00.640,0:43:03.760
conditional and so now in the last five

0:43:03.040,0:43:04.880
minutes

0:43:03.760,0:43:06.880
we're gonna be talking about the

0:43:04.880,0:43:08.240
self-supervised learning or the

0:43:06.880,0:43:10.400
conditional case

0:43:08.240,0:43:12.480
what does this mean so let's get back to

0:43:10.400,0:43:13.280
the training data this is my training

0:43:12.480,0:43:16.560
data right

0:43:13.280,0:43:19.119
we have we try to learn this horn

0:43:16.560,0:43:21.040
that is starting with a horizontal mouth

0:43:19.119,0:43:24.240
like it's like a closed mouth ah

0:43:21.040,0:43:27.680
like that and then it goes like a very

0:43:24.240,0:43:28.400
you know tall and narrow and then the

0:43:27.680,0:43:31.119
profile

0:43:28.400,0:43:31.760
the envelope is exponential right so

0:43:31.119,0:43:34.880
here

0:43:31.760,0:43:38.240
the the the radius

0:43:34.880,0:43:39.839
goes from beta to alpha and in x

0:43:38.240,0:43:41.839
in exp like it's multiplied by the

0:43:39.839,0:43:43.599
exponential of two times the x

0:43:41.839,0:43:45.920
and the other case the goes from alpha

0:43:43.599,0:43:46.640
to beta and also it is multiplied by

0:43:45.920,0:43:50.560
this

0:43:46.640,0:43:52.640
exponential so let's see if we can learn

0:43:50.560,0:43:54.960
this stuff and i didn't know if it was

0:43:52.640,0:43:58.160
easy or hard i thought it was hard

0:43:54.960,0:43:59.119
it was very easy and so untrained model

0:43:58.160,0:44:02.000
manifold

0:43:59.119,0:44:03.119
so let's give it a look how does my

0:44:02.000,0:44:05.920
model look now

0:44:03.119,0:44:07.359
so i have a z and since i have control

0:44:05.920,0:44:10.079
over z i take

0:44:07.359,0:44:12.079
you know zero to two pi to pi excluded

0:44:10.079,0:44:16.240
that's why the bracket is flipped

0:44:12.079,0:44:19.359
with an interval of pi over 24.

0:44:16.240,0:44:21.760
so i get a line on over there i fit this

0:44:19.359,0:44:22.480
z on the decoder and then i'm gonna get

0:44:21.760,0:44:25.440
my y

0:44:22.480,0:44:26.319
tilde which is gonna be moving uh like

0:44:25.440,0:44:28.800
going around

0:44:26.319,0:44:32.960
ellipses because that's how my network

0:44:28.800,0:44:35.359
is routed inside the decoder right

0:44:32.960,0:44:37.520
moreover we're gonna have our y's our

0:44:35.359,0:44:39.040
observer why is observed

0:44:37.520,0:44:41.280
you can see is observed because there is

0:44:39.040,0:44:44.160
a shade in that

0:44:41.280,0:44:45.200
bubble there in the circle and now we

0:44:44.160,0:44:47.920
have a predictor

0:44:45.200,0:44:48.319
and the decoder not only takes my latent

0:44:47.920,0:44:50.960
z

0:44:48.319,0:44:51.760
but also a predictor and the predictor

0:44:50.960,0:44:54.880
is fed

0:44:51.760,0:44:56.480
with my observed x and since again if i

0:44:54.880,0:44:59.760
have control over z

0:44:56.480,0:45:02.960
i can simply say it goes from 0 to 1

0:44:59.760,0:45:05.280
with 0.02 interval

0:45:02.960,0:45:07.520
let me show you how my untrained network

0:45:05.280,0:45:11.200
manifold looks right so this is what

0:45:07.520,0:45:13.599
this untrained network manifold looks

0:45:11.200,0:45:15.680
all right so how do i train this well i

0:45:13.599,0:45:19.359
just do the zero temperature limit

0:45:15.680,0:45:22.000
uh free energy training so given my

0:45:19.359,0:45:22.640
horn as before i take one point one y

0:45:22.000,0:45:25.200
point

0:45:22.640,0:45:25.839
i find the closest point on my manifold

0:45:25.200,0:45:27.839
and then

0:45:25.839,0:45:29.440
i try to pull it up i take this other

0:45:27.839,0:45:31.440
point i take the closest point

0:45:29.440,0:45:33.280
and i put it down there i take this

0:45:31.440,0:45:34.240
point over here i take the closest point

0:45:33.280,0:45:36.000
and then put it on

0:45:34.240,0:45:38.560
i take this point over here on the on

0:45:36.000,0:45:39.200
the horn i take the closest point on the

0:45:38.560,0:45:41.760
manifold

0:45:39.200,0:45:42.240
and i pull it down i do that for one

0:45:41.760,0:45:45.119
epoch

0:45:42.240,0:45:47.119
only i told you it was very easy to

0:45:45.119,0:45:49.839
train this model

0:45:47.119,0:45:51.599
and we get actually i had to define

0:45:49.839,0:45:53.359
first what is the energy function right

0:45:51.599,0:45:56.240
so my energy function

0:45:53.359,0:45:57.920
uh in this case is going to be this e of

0:45:56.240,0:46:01.200
x y and z

0:45:57.920,0:46:03.599
where again those two components uh like

0:46:01.200,0:46:05.040
it's going to be the sum of the square

0:46:03.599,0:46:08.560
distances

0:46:05.040,0:46:10.560
but in this case i have f and g right so

0:46:08.560,0:46:13.760
we have a predictor f

0:46:10.560,0:46:16.800
which are both of them mapping r to r r2

0:46:13.760,0:46:19.520
and then f is going to be a neural net

0:46:16.800,0:46:20.160
mapping my input x through a linear

0:46:19.520,0:46:22.720
layer and

0:46:20.160,0:46:23.440
reload to a eight dimensional hidden

0:46:22.720,0:46:25.280
layer

0:46:23.440,0:46:26.880
then i go again through another linear

0:46:25.280,0:46:28.000
layer and reload another eight

0:46:26.880,0:46:29.680
dimensional

0:46:28.000,0:46:31.760
hidden layer and then i have my final

0:46:29.680,0:46:32.880
linear layer to end up in two dimensions

0:46:31.760,0:46:36.400
so i have a four layer

0:46:32.880,0:46:38.560
network input two hidden of size eight

0:46:36.400,0:46:41.040
and then one output of size two

0:46:38.560,0:46:42.000
and then my g function is simply what

0:46:41.040,0:46:45.839
allows me to get

0:46:42.000,0:46:47.839
this z going in in loops okay

0:46:45.839,0:46:50.240
and but then the point now is that these

0:46:47.839,0:46:53.359
two components are going to be scaled

0:46:50.240,0:46:56.079
by the output of f

0:46:53.359,0:46:58.000
so this is my model very very tiny very

0:46:56.079,0:47:01.040
tiny model

0:46:58.000,0:47:01.760
and i'm going to be training it and then

0:47:01.040,0:47:04.480
i show you

0:47:01.760,0:47:05.040
the model manifold so again i take the

0:47:04.480,0:47:08.160
same

0:47:05.040,0:47:09.040
discretization for the znx and this is

0:47:08.160,0:47:13.040
how

0:47:09.040,0:47:16.240
the training train model manifold looks

0:47:13.040,0:47:17.839
it's awesome right i think it's just

0:47:16.240,0:47:19.839
great

0:47:17.839,0:47:21.119
all right and this one took nothing no

0:47:19.839,0:47:25.359
time to train

0:47:21.119,0:47:27.440
so how can we move on how

0:47:25.359,0:47:29.200
how what do we do next right how do we

0:47:27.440,0:47:31.760
move forward from here

0:47:29.200,0:47:34.079
so there are a few more ways to scale

0:47:31.760,0:47:36.079
this up not to toy example so

0:47:34.079,0:47:37.359
so far i've been kind of cheating right

0:47:36.079,0:47:40.800
i've been always

0:47:37.359,0:47:41.520
uh embedding into d decoder the fact

0:47:40.800,0:47:44.960
that my

0:47:41.520,0:47:45.359
z goes around circles but i don't know

0:47:44.960,0:47:48.160
that

0:47:45.359,0:47:49.920
right so we don't know that and so we

0:47:48.160,0:47:53.359
may use something like this

0:47:49.920,0:47:56.559
in this case my g function takes my

0:47:53.359,0:47:58.720
f and z

0:47:56.559,0:47:59.839
and then you know g can be a neural net

0:47:58.720,0:48:01.680
as well and

0:47:59.839,0:48:02.960
in this case i have to learn the fact

0:48:01.680,0:48:06.240
that this stuff

0:48:02.960,0:48:09.920
moves around circles so i in this case i

0:48:06.240,0:48:13.119
should be learning this sine and cosine

0:48:09.920,0:48:15.839
but then how do i know that actually

0:48:13.119,0:48:18.000
z is one dimensional well i know because

0:48:15.839,0:48:20.559
i generated my data right so

0:48:18.000,0:48:22.480
i am the owner of my data generation

0:48:20.559,0:48:25.680
process so i knew that

0:48:22.480,0:48:28.000
uh theta was a one-dimensional item so

0:48:25.680,0:48:29.359
definitely i can just use a latent that

0:48:28.000,0:48:31.040
is one-dimensional but

0:48:29.359,0:48:33.599
no one can tell me that for you know

0:48:31.040,0:48:36.079
natural images or whatever right so

0:48:33.599,0:48:37.760
that's the other big issue and so how

0:48:36.079,0:48:38.720
how would we deal with the fact that we

0:48:37.760,0:48:42.240
don't know

0:48:38.720,0:48:44.160
what is the correct size of my latent

0:48:42.240,0:48:45.839
uh because again if you choose a large

0:48:44.160,0:48:48.319
latent you're going to be

0:48:45.839,0:48:49.839
very easily overfitting everything and

0:48:48.319,0:48:51.520
so in this case

0:48:49.839,0:48:53.920
what changes from the previous slide

0:48:51.520,0:48:58.319
which is this one is that now z

0:48:53.920,0:49:00.400
is a vector okay so z is a vector

0:48:58.319,0:49:01.760
no longer just a single line so actually

0:49:00.400,0:49:03.200
this should be a vector and this should

0:49:01.760,0:49:06.640
be like whatever

0:49:03.200,0:49:09.680
the shape and now my g goes from

0:49:06.640,0:49:11.200
the dimension of f and you know

0:49:09.680,0:49:11.599
cartesian product with the dimension of

0:49:11.200,0:49:15.119
set

0:49:11.599,0:49:18.240
into r2 now the issue is that

0:49:15.119,0:49:20.640
we need to regularize

0:49:18.240,0:49:21.920
this loss functional because otherwise

0:49:20.640,0:49:23.040
you are going to be drastically over

0:49:21.920,0:49:25.280
fitting right

0:49:23.040,0:49:26.160
and so this is what current research

0:49:25.280,0:49:28.880
with jan

0:49:26.160,0:49:30.000
uh is now what me and my students are

0:49:28.880,0:49:32.559
doing

0:49:30.000,0:49:35.200
with jan we are trying to figure out

0:49:32.559,0:49:37.440
ways to regularize the latent variable

0:49:35.200,0:49:38.240
such that we can you know make things

0:49:37.440,0:49:42.480
actually not

0:49:38.240,0:49:44.640
simply overfit and that was it

0:49:42.480,0:49:45.680
that was all i had to tell you about

0:49:44.640,0:49:49.040
latent variable

0:49:45.680,0:49:51.680
energy-based models inference training

0:49:49.040,0:49:52.880
zero temperature limit a bit warmer than

0:49:51.680,0:49:55.680
free energy

0:49:52.880,0:49:56.240
uh and then we saw the unconditional

0:49:55.680,0:49:57.920
case

0:49:56.240,0:50:00.640
with unsupervised learning and then we

0:49:57.920,0:50:02.640
have seen the conditional case with the

0:50:00.640,0:50:04.240
uh self-supervised learning right where

0:50:02.640,0:50:07.280
we have access to these

0:50:04.240,0:50:09.760
acts and the code to train

0:50:07.280,0:50:11.760
these two models uh like the code that i

0:50:09.760,0:50:14.319
use for training the conditional case

0:50:11.760,0:50:16.480
it's just the same code as i use for the

0:50:14.319,0:50:18.160
unsupervised in a supervised case but

0:50:16.480,0:50:20.079
with one line change so

0:50:18.160,0:50:22.559
really really it doesn't take much

0:50:20.079,0:50:25.680
effort to put this together

0:50:22.559,0:50:28.240
what it took some effort was to draw

0:50:25.680,0:50:30.640
the slides but again that's just because

0:50:28.240,0:50:33.680
i like making things pretty

0:50:30.640,0:50:37.119
and that was it ah

0:50:33.680,0:50:39.440
thank you for listening questions please

0:50:37.119,0:50:41.520
go on i mean it's done right class is

0:50:39.440,0:50:44.720
finished

0:50:41.520,0:50:44.720
you can ask anything you want

0:50:45.200,0:50:48.000
are you still awake

0:50:51.280,0:50:55.119
yes okay someone is awake can you

0:50:53.040,0:50:57.359
explain the input dimension of

0:50:55.119,0:50:59.200
g again yes i can explain as much as you

0:50:57.359,0:51:00.240
want as you want so now it's office

0:50:59.200,0:51:02.880
hours right

0:51:00.240,0:51:04.400
you can ask anything you want uh hold on

0:51:02.880,0:51:05.839
first question so can you explain the

0:51:04.400,0:51:07.920
input dimension of g

0:51:05.839,0:51:09.680
uh in this case let me go back to the

0:51:07.920,0:51:13.200
first case

0:51:09.680,0:51:15.839
in this case g is 1 because it was

0:51:13.200,0:51:18.400
fed with z right and then the output was

0:51:15.839,0:51:20.559
this g1 and g2 which were cosine and

0:51:18.400,0:51:23.200
sine

0:51:20.559,0:51:24.559
in the second case g is going to be the

0:51:23.200,0:51:26.559
input is going to be this

0:51:24.559,0:51:28.160
f which we don't know exactly the

0:51:26.559,0:51:31.599
dimension can be anything

0:51:28.160,0:51:33.839
so the dimension of f and then

0:51:31.599,0:51:34.960
that given that i know that z is one

0:51:33.839,0:51:37.599
dimensional

0:51:34.960,0:51:38.079
finally which is the super you know norm

0:51:37.599,0:51:41.520
like

0:51:38.079,0:51:41.920
the actual case that the more realistic

0:51:41.520,0:51:44.640
case

0:51:41.920,0:51:45.520
is this one where we don't necessarily

0:51:44.640,0:51:48.079
know what is

0:51:45.520,0:51:48.720
the supposed the dimension for the

0:51:48.079,0:51:51.359
latent

0:51:48.720,0:51:53.359
and therefore now we're going to use a

0:51:51.359,0:51:54.800
whatever dimensional variable latent

0:51:53.359,0:51:58.000
variable but

0:51:54.800,0:51:59.280
it's going to be necessary to regularize

0:51:58.000,0:52:02.319
the

0:51:59.280,0:52:04.400
loss functional otherwise as i was

0:52:02.319,0:52:07.599
pointing out you can easily overfit

0:52:04.400,0:52:09.920
by using that zero temperature limit

0:52:07.599,0:52:11.359
uh nevertheless you can use you can warm

0:52:09.920,0:52:13.599
up the the temperature

0:52:11.359,0:52:15.280
and use that as a regularizer of course

0:52:13.599,0:52:18.880
right

0:52:15.280,0:52:21.520
did you get it uh yeah

0:52:18.880,0:52:23.200
so next question how does this look

0:52:21.520,0:52:24.960
without a latent variable

0:52:23.200,0:52:26.880
okay without a latent variable it's

0:52:24.960,0:52:30.079
exactly as turning

0:52:26.880,0:52:33.920
beta to zero okay

0:52:30.079,0:52:37.280
so beta to zero you just average

0:52:33.920,0:52:39.680
over all possible values how

0:52:37.280,0:52:41.599
does what does happen what what are you

0:52:39.680,0:52:44.319
going to be ending up having

0:52:41.599,0:52:44.800
if you start here on the left side and

0:52:44.319,0:52:47.119
then

0:52:44.800,0:52:47.920
instead of having all these arrows that

0:52:47.119,0:52:50.400
are shaped

0:52:47.920,0:52:51.119
now like that all these arrows will have

0:52:50.400,0:52:54.000
the same

0:52:51.119,0:52:55.599
length well actually these points over

0:52:54.000,0:52:56.880
here will be even longer now because

0:52:55.599,0:53:00.960
they are further away

0:52:56.880,0:53:03.280
so these ellipse will be pulled

0:53:00.960,0:53:04.559
in every direction and the way to

0:53:03.280,0:53:07.200
minimize this energy

0:53:04.559,0:53:08.480
is actually to make it collapse in a

0:53:07.200,0:53:12.079
single point

0:53:08.480,0:53:13.760
center in zero and so that's the actual

0:53:12.079,0:53:16.160
it's a very good question right so what

0:53:13.760,0:53:20.000
is the classical

0:53:16.160,0:53:22.000
failure mode in you know neural network

0:53:20.000,0:53:24.000
whenever you have multiple targets

0:53:22.000,0:53:26.880
associated to the same input

0:53:24.000,0:53:29.440
you end up predicting the average of all

0:53:26.880,0:53:31.520
the possible targets

0:53:29.440,0:53:32.960
in this case the average of all possible

0:53:31.520,0:53:34.640
targets that are all those

0:53:32.960,0:53:36.960
points in the ellipse is going to be

0:53:34.640,0:53:39.680
just the point in the origin

0:53:36.960,0:53:41.440
which is like the collapse of your model

0:53:39.680,0:53:42.880
right so that's a very good question and

0:53:41.440,0:53:46.480
the point is that

0:53:42.880,0:53:49.760
if you try to learn multi modal output

0:53:46.480,0:53:54.079
multimodal data set a data with

0:53:49.760,0:53:56.640
a msc like without latent with zero

0:53:54.079,0:53:57.440
zero beta infinite temperature you're

0:53:56.640,0:54:00.559
just you know

0:53:57.440,0:54:03.599
collapsing uh to the mean

0:54:00.559,0:54:04.000
the average right m e a and not m i n

0:54:03.599,0:54:07.280
mean

0:54:04.000,0:54:09.599
average all right another question

0:54:07.280,0:54:10.880
uh to be clear at the zero temperature

0:54:09.599,0:54:14.000
limit the loss

0:54:10.880,0:54:18.079
is only considering the energy

0:54:14.000,0:54:21.440
of the nearest point yeah

0:54:18.079,0:54:24.559
and as we warm it up the loss is using

0:54:21.440,0:54:26.640
a weighted sum of all points and yes

0:54:24.559,0:54:28.480
and the weighting weights that you're

0:54:26.640,0:54:30.480
using for the weight of the sum

0:54:28.480,0:54:31.760
is the are the weights that are coming

0:54:30.480,0:54:34.559
from the uh

0:54:31.760,0:54:36.000
soft argument right if you take the arg

0:54:34.559,0:54:38.400
softening

0:54:36.000,0:54:39.760
you have soft mean of the energy right

0:54:38.400,0:54:41.920
so that's what you get

0:54:39.760,0:54:44.160
you have the soft mean of the energy

0:54:41.920,0:54:45.280
right so the f tilde it's soft mean of

0:54:44.160,0:54:48.240
the energy

0:54:45.280,0:54:49.520
you take the derivative of the softmin

0:54:48.240,0:54:51.440
you get the

0:54:49.520,0:54:53.680
what you get you get the exponential

0:54:51.440,0:54:56.160
divided by the sum of exponential

0:54:53.680,0:54:56.799
so that's the soft argument right

0:54:56.160,0:55:00.160
multiply

0:54:56.799,0:55:03.359
by e prime what is e prime e

0:55:00.160,0:55:04.960
was the square distance so if you take

0:55:03.359,0:55:05.599
the derivative of the square distance

0:55:04.960,0:55:08.319
you just get

0:55:05.599,0:55:10.079
the vector which is now multiplied by

0:55:08.319,0:55:12.559
this soft argument

0:55:10.079,0:55:13.359
so exactly what you said uh which is

0:55:12.559,0:55:15.839
very good

0:55:13.359,0:55:18.000
summary i'm gonna just read it again and

0:55:15.839,0:55:21.119
i show the other chart

0:55:18.000,0:55:22.720
so i just read your comment

0:55:21.119,0:55:25.119
to be clear at the zero temperature

0:55:22.720,0:55:26.799
limit the loss is only considering the

0:55:25.119,0:55:28.480
energy of the nearest point

0:55:26.799,0:55:29.839
the distance the square distance to the

0:55:28.480,0:55:31.599
closest point yeah

0:55:29.839,0:55:34.160
and as you warm it up the loss is going

0:55:31.599,0:55:37.200
to be the weighted sum

0:55:34.160,0:55:42.480
of not the points right what is sum uh

0:55:37.200,0:55:45.599
of all those um contributions right

0:55:42.480,0:55:46.319
the x uh this exponential of the minus

0:55:45.599,0:55:49.119
beta e

0:55:46.319,0:55:50.319
right that's what that was written here

0:55:49.119,0:55:51.760
on the top right

0:55:50.319,0:55:53.760
so as you warm it up you're going to get

0:55:51.760,0:55:56.160
this exponential which is the soft mean

0:55:53.760,0:55:56.799
so soft mean and then if you compute the

0:55:56.160,0:55:59.280
uh

0:55:56.799,0:56:00.960
the derivative you're going to get the

0:55:59.280,0:56:02.640
soft argument multiplied by the

0:56:00.960,0:56:04.400
derivative of the energy

0:56:02.640,0:56:06.319
which are the arrows multiplied by the

0:56:04.400,0:56:09.359
soft argument so cool

0:56:06.319,0:56:10.799
what happens if we allow z to move

0:56:09.359,0:56:13.839
freely into the space

0:56:10.799,0:56:15.839
we're going to basically get a collapsed

0:56:13.839,0:56:17.119
network this model can simply output

0:56:15.839,0:56:20.640
zero everywhere

0:56:17.119,0:56:21.520
and that's where you may need to use the

0:56:20.640,0:56:24.559
contrastive

0:56:21.520,0:56:26.319
uh cases right so in that case uh you

0:56:24.559,0:56:28.319
know a very easy way to get

0:56:26.319,0:56:31.200
zero energy is gonna be just everything

0:56:28.319,0:56:33.119
zero right uh but in this in the

0:56:31.200,0:56:35.599
in this case you can use the contrastive

0:56:33.119,0:56:37.760
case you can say oh no in this case it

0:56:35.599,0:56:40.720
should be larger than some margin

0:56:37.760,0:56:42.319
and so that's how you can deal with this

0:56:40.720,0:56:45.760
larger than uh

0:56:42.319,0:56:48.880
like z into d okay so

0:56:45.760,0:56:49.520
taking beta okay so taking beta uh to

0:56:48.880,0:56:51.760
zero

0:56:49.520,0:56:53.839
would defeat the purpose of having a

0:56:51.760,0:56:54.319
latent variable at all that's exactly

0:56:53.839,0:56:56.720
yeah

0:56:54.319,0:56:58.480
and so this is what i kind of briefly

0:56:56.720,0:57:02.400
show you i didn't talk about

0:56:58.480,0:57:04.160
but this is like a a quick uh derivation

0:57:02.400,0:57:06.559
by showing you that if you go beta

0:57:04.160,0:57:07.440
equals zero like the limit for beta that

0:57:06.559,0:57:10.480
tends to zero

0:57:07.440,0:57:11.440
you retrieve the average across all the

0:57:10.480,0:57:14.640
latent

0:57:11.440,0:57:16.079
and that's basically the you end up with

0:57:14.640,0:57:18.240
having msc right

0:57:16.079,0:57:19.920
you end up throwing away all those kind

0:57:18.240,0:57:23.760
of uh the goodies

0:57:19.920,0:57:26.319
right and that was pretty much it

0:57:23.760,0:57:28.480
how can you get more out of this lesson

0:57:26.319,0:57:30.480
firstly comprehension

0:57:28.480,0:57:33.119
if anything was not clear ask me

0:57:30.480,0:57:34.480
anything in the comment section below

0:57:33.119,0:57:36.640
if you would like to follow up with the

0:57:34.480,0:57:39.760
latest news follow me on twitter

0:57:36.640,0:57:42.160
under the endl alph cnz

0:57:39.760,0:57:44.000
if you would like to be notified when i

0:57:42.160,0:57:45.680
upload the latest video

0:57:44.000,0:57:47.839
don't forget to subscribe to the channel

0:57:45.680,0:57:50.079
and turn on the notification bell

0:57:47.839,0:57:52.000
and if you like this video don't forget

0:57:50.079,0:57:54.400
to put a thumb up

0:57:52.000,0:57:55.920
this video has a transcript in english

0:57:54.400,0:57:57.359
and if you would like to contribute to

0:57:55.920,0:58:00.160
the translation in your language

0:57:57.359,0:58:01.839
please let me know so here as you can

0:58:00.160,0:58:05.359
see we have the

0:58:01.839,0:58:07.920
write up where we can see all these

0:58:05.359,0:58:10.319
video that has been transcribed here in

0:58:07.920,0:58:13.040
plain english

0:58:10.319,0:58:14.240
and then again as i said before if we go

0:58:13.040,0:58:16.240
back to the homepage

0:58:14.240,0:58:18.720
we can see here in the english flag and

0:58:16.240,0:58:20.799
we can select different languages

0:58:18.720,0:58:22.079
now we have arabic spanish version

0:58:20.799,0:58:24.960
french italian japanese

0:58:22.079,0:58:25.920
korean russian turkish and chinese and

0:58:24.960,0:58:28.640
your language is just

0:58:25.920,0:58:29.359
waiting for you to be translated in

0:58:28.640,0:58:31.599
finally

0:58:29.359,0:58:32.960
do play with notebook and by torch in

0:58:31.599,0:58:35.520
order to get yourself

0:58:32.960,0:58:36.640
more acquainted with all these new

0:58:35.520,0:58:38.880
topics

0:58:36.640,0:58:41.040
and then if you find any typo or

0:58:38.880,0:58:41.520
mistakes or anything just please let me

0:58:41.040,0:58:43.760
know

0:58:41.520,0:58:46.079
directly on github or if you feel brave

0:58:43.760,0:58:48.960
enough you can even send a pull request

0:58:46.079,0:58:51.280
it will be gladly appreciated thank you

0:58:48.960,0:58:54.240
for listening and don't forget to like

0:58:51.280,0:58:54.240
share and subscribe

0:58:55.000,0:58:58.000
bye

